{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas for Data Manipulation\n",
    "### USI ARA AAM, Nov 19\n",
    "\n",
    "## Notebook Material Credits\n",
    "- Alfred Essa ( @alfessa )\n",
    "- Harrison Kinsley ( @sentdex )\n",
    "- Verena Kaynig-Fittkau (Harvard CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is pandas?\n",
    "\n",
    "Pandas is one of the most popular tools for data wrangling in python. In essence, pandas is the equivalent of data frames in R. Additionally, it is tightly tied with numpy and matplotlib. This allows it to be readily amenable to modeling (in scikit-learn) and plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Importing modules\n",
    "\n",
    "To start off we shall import the most basic modules that work with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this allows you to plot and display within the notebook environment\n",
    "%matplotlib inline    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas Series\n",
    "\n",
    "The most basic pandas data structure is a *Series* object. A Series **ducktypes** as an numpy array as well as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s1= pd.Series([33,19,15,89,11,-5,9])\n",
    "print type(s1)\n",
    "print s1\n",
    "print s1[0],s1[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Index in a Series\n",
    "\n",
    "A pandas Series has an **index** that you can optionally specify. If unspecified, it becomes a simple serial number like above. The index is like a reference to the row - it says what that entry is about. Here is an example of a Series that records the temperature on 7 days of a week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data1= [33,19,15,89,11,-5,9]\n",
    "index1= ['mon','tue','wed','thu','fri','sat','sun']\n",
    "s2= pd.Series(data1, index=index1)\n",
    "print s2, \"\\n\"\n",
    "\n",
    "print s2['mon'], \"\\n\"\n",
    "print s2['wed':'fri'], \"\\n\"\n",
    "print s2[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is possible for you to give names to your index and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s2.name= 'Daily temperature'\n",
    "s2.index.name= 'Weekday'\n",
    "print s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Series from a dictionary\n",
    "\n",
    "As you might have guessed by now, the reason Series behaves like a dictionary is because of this index. Thus, you can create a Series out of a dict, and the dict keys become the indices. There is a catch, though. Pandas will *rearrange* the indices in alphabetic / numeric sort order (which might not be what you wanted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dict1= {'mon':33, 'tue':19.7, 'wed':15, 'thu':89, 'fri': 34, 'sat': 43, 'sun': 51}\n",
    "s4= pd.Series(dict1)\n",
    "print s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To remedy this you need to specify the index in the way you want it, while the data can come from the dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s4= pd.Series(dict1, index= index1)\n",
    "print s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Just like a dict, you can iterate over the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in s4.iteritems():\n",
    "    print k, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Also, just like a dictionary, you can operate on the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print s4['thu'], \"\\n\\n\"\n",
    "print s4[3], \"\\n\\n\"\n",
    "print 'sun' in s4, \"\\n\\n\"\n",
    "print 'moon' in s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorized operations\n",
    "\n",
    "Because Series is derived from  a numpy array, it allows numpy functions and vectorized operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print s4.sum(), \"\\n\\n\"\n",
    "print s4.median(), \"\\n\\n\"\n",
    "print s4.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print s4 **2, \"\\n\\n\"\n",
    "print s4 + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can also perform list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "new = [x**2 for x in s4]\n",
    "print new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas DataFrame\n",
    "\n",
    "While pandas Series are interesting, they are not too useful - you can make do with dicts and arrays ni place of Series. Pandas becomes really useful with its next datastructure - the *DataFrame*. DataFrame is a set of Series objects stacked horizontally together across a single index for each row. As you might imagine, this is essentially data like a spreadsheet, in rows and columns. This is the most common format data scientists use on a daily basis. \n",
    "\n",
    "You can create your own dataframes as demonstrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dtm\n",
    "\n",
    "dt= dtm.datetime(2014,12,1)\n",
    "en= dtm.datetime(2014,12,8)\n",
    "step= dtm.timedelta(days=1)\n",
    "dates= []\n",
    "while dt < en:\n",
    "    dates.append(dt.strftime('%Y-%m-%d'))\n",
    "    dt += step\n",
    "print dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "t1= [15,19,15,11,9,8,13]\n",
    "t2= [20,18,23,19,25,27,23]\n",
    "t3= [-2,0,2,5,7,-5,-3]\n",
    "d= {'Date': dates,'Tokyo': t1, 'Mumbai': t2, 'Paris': t3}\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "temps= pd.DataFrame(d)\n",
    "temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each column in the dataset is a Series, and it can be referenced using the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print type(temps['Mumbai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can define the index in the dataframe using the `set_index` command. Note that some pandas commands like `set_index` do not update the dataframe directly. So you have to over-write the dataframe for the changes to take effect. We shall see a different way of doing it shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temps= temps.set_index('Date') \n",
    "#you cannot repeat this command!!\n",
    "temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rows and Columns\n",
    "\n",
    "The most basic thing you want to do on the data frame is to be able to access its rows and columns for data. This can be done using column names and indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "days= pd.date_range('2014-01-01', '2014-03-01', freq= 'D')\n",
    "dim= (60,5)\n",
    "df= pd.DataFrame(np.random.random_integers(-20,40,dim),\n",
    "                index= days,\n",
    "                columns= ['Madrid','Boston','Tokyo','Shanghai','Kolkata'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print df.shape, \"\\n\\n\"\n",
    "print len(df), \"\\n\\n\"\n",
    "print df.columns.values, \"\\n\\n\"\n",
    "print len(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Column Selection\n",
    "\n",
    "You can select columns by referring to the column name. Use a list of columns to pick multiple columns - this returns a smaller dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print df.Madrid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print df['Tokyo'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[['Boston', 'Shanghai']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Row selection \n",
    "\n",
    "You can select rows by using the *ix* function. Note that there are 2 other functions: *loc* and *iloc*. Read about the subtle differences [here](http://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation). I personally prefer using **ix** since its a wrapper on the others. And then again, mostly nobody selects rows by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.ix['2014-01-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.ix['2014-01-24':'2014-01-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, you can combine row and column selection to pick out a smaller dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.ix['2014-02-10':'2014-02-15', ['Madrid', 'Kolkata']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Logical Indexing of Rows \n",
    "\n",
    "Rarely do we select rows directly by their row number. Sometimes selecting by index may be useful. But the most widely used row selection technique in data science is *logical indexing* , which is a fancy term that means *conditional to values in some column(s)*. Let us see this in the next example where we import an external data frame for the first time in this lesson. This too, is the de-facto standard (needless to say)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "auto= pd.read_csv('../data/auto.csv')\n",
    "print auto.shape\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can select on a column by filtering a logical condition on that column as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a1= auto[auto['foreign']==1]\n",
    "a1.shape\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This works because the condition in itself returns a boolean array, which can then be used to perform the indexing. Numpy provides a quick way of reversing the boolean array (logical **NOT**) too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mask= auto['foreign']==1\n",
    "print mask.sum()\n",
    "domestic= auto[np.invert(mask)]\n",
    "print domestic.shape\n",
    "domestic.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Naturally, you can combine multiple columns to make a condition. *Unlike* what you might expect, the usual `and` does not work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 'and' does not work here!\n",
    "a2= auto[(auto['mpg'] > 20) and (auto['price'] < 5000)]     \n",
    "a2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applying Calculations on Columns\n",
    "\n",
    "Columns are only useful when we can do something with the data in them. We frequently apply various computations on columns. In the following example with another dataset, we shall see some common operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mlb= pd.read_csv('../data/mlbsalaries.csv')\n",
    "print mlb.shape\n",
    "mlb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sorting a column\n",
    "\n",
    "Sorting a particular column is easily done with the `sort_values` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss= mlb['Salary'].sort_values(ascending=False)\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is barely useful though, since it only returns the column itself. To sort the whole dataset, use the `sort_values` method with a `by` qualifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf= mlb.sort_values(ascending=False, by= ['Salary'])\n",
    "sf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can also sort on multiple columns simultaneously, using a list of columns and their ordering strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf= mlb.sort_values(ascending=[False, False], by= ['Salary','Year'])\n",
    "sf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A very useful command is `value_counts`. Essentialy, it counts the number of records for each unique value in a given column. Naturally, it is useful when applied to categorical columns. However, this can only be applied on one column at a time. There is a way to do this for more than one column - we'll come to it shortly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mlb['Position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can do all the usual commands on a column, since it is a numpy array at its core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print mlb['Salary'].max(), \"\\n\\n\"\n",
    "print mlb['Salary'].mean(), \"\\n\\n\"\n",
    "print mlb['Salary'].min(), \"\\n\\n\"\n",
    "print mlb['Salary'].median(), \"\\n\\n\"\n",
    "print mlb['Salary'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But interestingly you can apply the same function to multiple columns by simply calling it on part or whole of the dataframe. The result is returned as an indexed series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mlb[['Year', 'Salary']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "auto.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto['wt_per_len']= auto['weight'] / auto['length']\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is possible to define a column conditional on another column. Its a little tricky and needs use of a numpy function `where`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "auto['adjusted_price']= np.where(auto['foreign']==0, auto['price'], auto['price'] * 1.1)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, for a quick summary of descriptive statistics on each *numeric* column, the `describe` method is very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "auto.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can drop one or more columns with the drop function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# this needs to be saved!\n",
    "auto.drop('wt_per_len', axis= 1)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For long continuous values it is better to visualize the distribution using a histogram / boxplot / violin plot (later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mlb['Salary'].hist(bins= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mlb.boxplot(column= 'Salary', return_type= 'dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A little more code allows us to plot the top salaries in a recent year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "yr2010= mlb[mlb['Year']==2010]\n",
    "yr2010.set_index('Player', inplace=True)\n",
    "yr2010.head()\n",
    "top10= yr2010['Salary'].sort_values(ascending= False).head(10)\n",
    "plt.figure()\n",
    "top10.plot(kind= 'bar', label= 'Salaries in 2010')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grouping pandas dataframes\n",
    "\n",
    "Impressive as the last bit of code is, it is difficult to do it for every year in the data. This is where the power of **split-apply-combine** methods become apparent. In pandas, this is implemented through the `groupby` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped= mlb.groupby('Year')\n",
    "type(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One problem of a grouped object is that its not so easy to look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "i= 0\n",
    "for k,grp in grouped:\n",
    "    i += 1\n",
    "    if i >= 4:\n",
    "        break\n",
    "    print k\n",
    "    print grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Findng the top salary per group is not too hard, using a `max` on the grouped object. Similarly many other normal functions can be applied directly on the grouped object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped['Salary'].max().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An interesting thing about grouped objects is that it allows you to apply multiple functions on multiple columns using the `agg` method. This is a useful method to apply generic functions on a grouped object. Unfortunately, `agg` cannot be used directly on dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ll= auto.groupby('make', as_index= False).agg( {'price': np.mean, \n",
    "                                                'weight': np.std, \n",
    "                                                'length': np.max, \n",
    "                                                'adjusted_price': np.median} )\n",
    "ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But now the goal is to find the player with the highest salary in each year. This is more tricky! Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k= (grp.sort_values(by= 'Salary', ascending= False)[:1] for yr,grp in grouped)\n",
    "topSalaries= pd.DataFrame()\n",
    "for line in k:\n",
    "    topSalaries= topSalaries.append(line)\n",
    "topSalaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ts= topSalaries[['Year', 'Salary']]\n",
    "ts= ts.set_index('Year')\n",
    "ts.plot(kind= 'bar', color= 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped= mlb.groupby('Position')\n",
    "grouped['Salary'].median().plot(kind= 'bar', color= 'green', label= 'Median Salaries by Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mlb.boxplot(column= 'Salary', by= 'Position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to go Next\n",
    "\n",
    "[Pandas documentation & Cookbook](http://pandas.pydata.org/pandas-docs/stable/cookbook.html) -- the customary doc link\n",
    "\n",
    "[Python for Data Analysis](http://www.cin.ufpe.br/~embat/Python%20for%20Data%20Analysis.pdf)  -- Wes McKinney\n",
    "\n",
    "[CS 109](http://cs109.github.io/2015/) Harvard CS Online Course (Hosted on Github)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lambda Functions, `map`, `apply` and `applymap`\n",
    "\n",
    "## Joining and Merging datasets in pandas\n",
    "\n",
    "\n",
    "   Until.... next time!      -- *Harrison*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
